{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Version 7.1.0 of praw is outdated. Version 7.1.2 was released 21 hours ago.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "Social Media Opinion Mining App\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Choose a platform: \n",
      "{'1': 'Twitter', '2': 'Reddit'}\n",
      "2\n",
      "\n",
      "====================================================================================================\n",
      "Retrieve Reddit Submissions and Comments with PRAW\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Would you like to execute a schedule? ['Y', 'N']\n",
      "N\n",
      "\n",
      "Enter a search term.\n",
      "m1\n",
      "\n",
      "Enter a limit.\n",
      "5\n",
      "\n",
      "Enter a list of subreddits seperated by commas.\n",
      "Apple, mac\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "Summary of Query\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Check your responses carefully to avoid wasting API calls.\n",
      "\n",
      "==============================\n",
      "Search term:  m1\n",
      "Limit:  5\n",
      "Subreddits: ['Apple', 'mac']\n",
      "==============================\n",
      "\n",
      "Are you happy with your query? ['Y', 'N']\n",
      "Y\n",
      "\n",
      "[*] Generating Query...\n",
      "\n",
      "[*] Retrieving data from r/Apple\n",
      "\n",
      "[*] Searching for [m1] in [r/Apple]...\n",
      "\n",
      "[*] Searching for [m1] in comments for [r/Apple]...\n",
      "\n",
      "[*] Saving results to  ~/AppleM1SentimentAnalysis/data/reddit_data/raw_data/subred_data/2021-02-04_12_53_50.csv\n",
      "\n",
      "[*] Retrieving data from r/mac\n",
      "\n",
      "[*] Searching for [m1] in [r/mac]...\n",
      "\n",
      "[*] Searching for [m1] in comments for [r/mac]...\n",
      "\n",
      "[*] Saving results to  ~/AppleM1SentimentAnalysis/data/reddit_data/raw_data/subred_data/2021-02-04_12_53_50.csv\n",
      "\n",
      "Would you like to preprocess the data? ['Y', 'N']\n",
      "Y\n",
      "\n",
      "====================================================================================================\n",
      "Preprocess Data\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[*] Retrieving session data from source directory...\n",
      "\n",
      "[*] Adding  2021-01-12_12_07_16.csv to batch:  2021-02-04_12_56_03.csv\n",
      "[*] Adding  2021-01-29_08_48_21.csv to batch:  2021-02-04_12_56_03.csv\n",
      "[*] Adding  2021-01-12_11_59_17.csv to batch:  2021-02-04_12_56_03.csv\n",
      "[*] Adding  2021-01-12_12_07_01.csv to batch:  2021-02-04_12_56_03.csv\n",
      "[*] Adding  2021-01-12_11_59_15.csv to batch:  2021-02-04_12_56_03.csv\n",
      "[*] Adding  2021-01-20_10_46_39.csv to batch:  2021-02-04_12_56_03.csv\n",
      "[*] Adding  2021-01-12_12_07_11.csv to batch:  2021-02-04_12_56_03.csv\n",
      "[*] Adding  2021-01-29_08_52_40.csv to batch:  2021-02-04_12_56_03.csv\n",
      "[*] Adding  2021-01-12_12_07_06.csv to batch:  2021-02-04_12_56_03.csv\n",
      "[*] Adding  2021-01-29_08_55_13.csv to batch:  2021-02-04_12_56_03.csv\n",
      "[*] Adding  2021-01-12_12_10_44.csv to batch:  2021-02-04_12_56_03.csv\n",
      "[*] Adding  2021-01-28_20_31_58.csv to batch:  2021-02-04_12_56_03.csv\n",
      "[*] Adding  2021-01-29_08_46_44.csv to batch:  2021-02-04_12_56_03.csv\n",
      "[*] Adding  2021-01-28_20_30_31.csv to batch:  2021-02-04_12_56_03.csv\n",
      "[*] Adding  2021-01-28_20_27_04.csv to batch:  2021-02-04_12_56_03.csv\n",
      "[*] Adding  2021-01-12_12_10_54.csv to batch:  2021-02-04_12_56_03.csv\n",
      "[*] Adding  2021-01-28_20_36_42.csv to batch:  2021-02-04_12_56_03.csv\n",
      "[*] Adding  2021-01-29_08_50_29.csv to batch:  2021-02-04_12_56_03.csv\n",
      "[*] Adding  2021-01-28_20_35_21.csv to batch:  2021-02-04_12_56_03.csv\n",
      "[*] Adding  2021-01-20_10_47_17.csv to batch:  2021-02-04_12_56_03.csv\n",
      "[*] Adding  2021-01-28_20_15_41.csv to batch:  2021-02-04_12_56_03.csv\n",
      "[*] Adding  2021-01-20_10_47_10.csv to batch:  2021-02-04_12_56_03.csv\n",
      "[*] Adding  2021-01-12_12_10_48.csv to batch:  2021-02-04_12_56_03.csv\n",
      "[*] Adding  2021-01-29_08_54_39.csv to batch:  2021-02-04_12_56_03.csv\n",
      "[*] Adding  2021-01-28_20_28_38.csv to batch:  2021-02-04_12_56_03.csv\n",
      "[*] Adding  2021-01-12_12_00_17.csv to batch:  2021-02-04_12_56_03.csv\n",
      "[*] Adding  2021-01-12_12_00_10.csv to batch:  2021-02-04_12_56_03.csv\n",
      "[*] Adding  2021-01-20_10_46_31.csv to batch:  2021-02-04_12_56_03.csv\n",
      "[*] Adding  2021-01-20_10_46_25.csv to batch:  2021-02-04_12_56_03.csv\n",
      "\n",
      "[*] Preprocessing batch: 2021-02-04_12_56_03.csv\n",
      "\n",
      "[*] Intiating text cleaning...\n",
      "-- Tokenizing...\n",
      "-- Removing non-alphabetic characters...\n",
      "-- Converting to lowercase...\n",
      "-- Removing hashtags, web addresses, and mentions...\n",
      "-- Removing any code tags...\n",
      "-- Joining tokens for further processing...\n",
      "\n",
      "[*] Labeling subjectivity...\n",
      "-- Calculating subjectivity scores...\n",
      "\n",
      "[*] Labeling polarity...\n",
      "-- Calculating polarity scores...\n",
      "-- Determining polarity label...\n",
      "Would you like to eliminate the neutral class? ['Y', 'N']\n",
      "Y\n",
      "\n",
      "[*] Processing text...\n",
      "-- Removing stopwords...\n",
      "-- Lemmatizing tokens...\n",
      "\n",
      "[*] Calculating text length...\n",
      "\n",
      "[*] Applying POS tags...\n",
      "-- Obtaining POS tags...\n",
      "-- Creating POS tag list...\n",
      "-- Counting POS tags...\n",
      "\n",
      "[*] Preprocessing Complete\n",
      "\n",
      "[*] Saving processed results to  /Users/christineegan/AppleM1SentimentAnalysis/data/reddit_data/labeled_data/2021-02-04_14_36_04.csv\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '/Users/christineegan/AppleM1SentimentAnalysis/src')\n",
    "\n",
    "import general_functions\n",
    "import twitter_api\n",
    "import reddit_api\n",
    "import process_data\n",
    "import eda_visualizations\n",
    "import word_vector_functions\n",
    "import model_functions\n",
    "\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    general_functions.create_banner('Social Media Opinion Mining App')\n",
    "    \n",
    "    platforms = {'1': 'Twitter', '2': 'Reddit'}\n",
    "    print('')\n",
    "    print('Choose a platform: ')\n",
    "    print(platforms)\n",
    "    platform = input()\n",
    "\n",
    "    # choose a platform\n",
    "    while platform not in list(platforms.keys()):\n",
    "        print('\\nInput not recognized. Try again.')\n",
    "        platform = input()\n",
    "\n",
    "    if platform == '1':\n",
    "        general_functions.create_banner('Retrieve Tweets with Twython')\n",
    "        answers = ['Y', 'N']\n",
    "        print('\\nWould you like to execute a schedule?', answers)\n",
    "        answer = input()\n",
    "        \n",
    "        while answer.upper() not in answers:\n",
    "            print('\\nInput not recognized. Try again.')\n",
    "            answer = input()\n",
    "            \n",
    "        if answer.upper == answers[0]:\n",
    "            print('\\n[*] Launching Schedule...')\n",
    "            general_functions.execute_schedule('Twitter')\n",
    "            print('\\nWould you like to preprocess the data?', answers)\n",
    "            answer = input()\n",
    "            \n",
    "            while answer.upper() not in answers:\n",
    "                print('\\nInput not recognized. Try again.')\n",
    "                answer = input()\n",
    "                \n",
    "            if answer.upper() == answers[0]:\n",
    "                process_data.batch_and_process_data('Twitter')\n",
    "#                 print('\\n[*] Would you like to model the data?')\n",
    "#                 answer = input()\n",
    "                \n",
    "#                 if answer.upper() == answers[0]:\n",
    "#                     model_functions.execute_models()\n",
    "                    \n",
    "#                 else:\n",
    "#                     print('\\n[*] Session Ended.')\n",
    "   \n",
    "            elif answer.upper() == answers[1]:\n",
    "                print('\\n[*] Session Ended.')             \n",
    "\n",
    "        else:\n",
    "            q, result_type, count = twitter_api.tweet_params()\n",
    "            query = twitter_api.tweet_query_summary(q, result_type, count)\n",
    "            twitter_api.retrieve_tweets(query)\n",
    "            \n",
    "            print('\\nWould you like to preprocess the data?', answers)\n",
    "            answer = input()\n",
    "            \n",
    "            while answer.upper() not in answers:\n",
    "                print('\\nInput not recognized. Try again.')\n",
    "                answer = input()\n",
    "                \n",
    "            if answer.upper() == answers[0]:\n",
    "                process_data.batch_and_process_data('Twitter')\n",
    "#                 print('\\n[*] Would you like to model the data?', answers)\n",
    "#                 answer = input()\n",
    "                \n",
    "#                 if answer.upper() == answers[0]:\n",
    "#                     model_functions.execute_models()\n",
    "                    \n",
    "#                 else:\n",
    "#                     print('\\[*] Session Ended.')\n",
    "                \n",
    "            elif answer.upper() == answers[1]:\n",
    "                print('\\n[*] Session Ended.')\n",
    "\n",
    "    elif platform == '2':\n",
    "        general_functions.create_banner('Retrieve Reddit Submissions and Comments with PRAW')\n",
    "\n",
    "        answers = ['Y', 'N']\n",
    "        print('\\nWould you like to execute a schedule?', answers)\n",
    "        answer = input()\n",
    "        \n",
    "        while answer.upper() not in answers:\n",
    "            print('\\nInput not recognized. Try again.')\n",
    "            answer = input()\n",
    "            \n",
    "        if answer.upper() == answers[0]:\n",
    "            print('\\n[*] Launching Schedule...')\n",
    "            general_functions.execute_schedule('Reddit')\n",
    "            print('\\nWould you like to preprocess the data?', answers)\n",
    "            answer = input()\n",
    "            \n",
    "            while answer.upper() not in answers:\n",
    "                print('\\nInput not recognized. Try again.')\n",
    "                answer = input()\n",
    "                \n",
    "            if answer.upper() == answers[0]:\n",
    "                process_data.batch_and_process_data('Reddit')\n",
    "#                 print('\\n[*] Would you like to model the data?', answers)\n",
    "#                 answer = input()\n",
    "                \n",
    "#                 if answer.upper() == answers[0]:\n",
    "#                     model_functions.execute_models()\n",
    "                    \n",
    "#                 else:\n",
    "#                     print('\\[*] Session Ended.')\n",
    "                \n",
    "            elif answer.upper() == answers[1]:\n",
    "                print('\\n[*] Session Ended.')\n",
    "\n",
    "        # conduct one session\n",
    "        else:\n",
    "            term, limit, subreds = reddit_api.submissions_params()\n",
    "            term, limit, subreds = reddit_api.reddit_query_summary(term, limit, subreds)\n",
    "            reddit_api.retrieve_submissions(term, limit, subreds)\n",
    "\n",
    "            print('\\nWould you like to preprocess the data?', answers)\n",
    "            answer = input()\n",
    "            \n",
    "            while answer.upper() not in answers:\n",
    "                print('\\nInput not recognized. Try again.')\n",
    "                answer = input()\n",
    "                \n",
    "            if answer.upper() == answers[0]:\n",
    "                process_data.batch_and_process_data('Reddit')\n",
    "#                 print('\\n[*] Would you like to model the data?', answers)\n",
    "#                 answer = input()\n",
    "                \n",
    "#                 if answer.upper() == answers[0]:\n",
    "#                     model_functions.execute_models()\n",
    "                    \n",
    "#                 else:\n",
    "#                     print('\\[*] Session Ended.')\n",
    "                \n",
    "            elif answer.upper() == answers[1]:\n",
    "                print('\\n[*] Session Ended.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "apple_m1_env",
   "language": "python",
   "name": "apple_m1_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
